<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.290">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mark Spillman">
<meta name="dcterms.date" content="2024-02-17">
<meta name="description" content="Using convolutional transformer encoders to detect multi-phase PXRD patterns">

<title>Mark Spillman - Detecting Impurities in PXRD data</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-EVMREB130B"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-EVMREB130B', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Mark Spillman</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../publications.html" rel="" target="">
 <span class="menu-text">Publications</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/mspillman" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/mspillman" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../index.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Detecting Impurities in PXRD data</h1>
                  <div>
        <div class="description">
          Using convolutional transformer encoders to detect multi-phase PXRD patterns
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">PXRD</div>
                <div class="quarto-category">Machine learning</div>
                <div class="quarto-category">Synthetic data</div>
                <div class="quarto-category">Impurities</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Mark Spillman </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 17, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#impurities-and-indexing" id="toc-impurities-and-indexing" class="nav-link" data-scroll-target="#impurities-and-indexing">Impurities and Indexing</a></li>
  </ul></li>
  <li><a href="#neural-network-architecture" id="toc-neural-network-architecture" class="nav-link" data-scroll-target="#neural-network-architecture">Neural network architecture</a></li>
  <li><a href="#web-app" id="toc-web-app" class="nav-link" data-scroll-target="#web-app">Web-App</a>
  <ul class="collapse">
  <li><a href="#how-it-works" id="toc-how-it-works" class="nav-link" data-scroll-target="#how-it-works">How it works</a></li>
  </ul></li>
  <li><a href="#conclusions" id="toc-conclusions" class="nav-link" data-scroll-target="#conclusions">Conclusions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>In my <a href="https://mspillman.github.io/blog/posts/2024-02-11-Indexing-PXRD-data-with-Convolutional-Neural-Networks.html">previous post</a>, I replicated the results of an article by <a href="https://scripts.iucr.org/cgi-bin/paper?vb5020">Chitturi and coworkers</a>, who showed that convolutional neural networks can be used to determine unit cell edge lengths directly from PXRD data with a relatively good level of precision. I was able to both improve on their results and reduce the parameter count of the neural network by updating the architecture used.</p>
<p>In this post, we’ll look at an application of neural networks that I’ve not yet seen in the literature.</p>
<section id="impurities-and-indexing" class="level2">
<h2 class="anchored" data-anchor-id="impurities-and-indexing">Impurities and Indexing</h2>
<p>One thing that can severely hamper our ability to index a powder diffraction pattern is the presence of peaks coming from minority (i.e.&nbsp;impurity) phases in the sample. If the sample contains multiple crystalline phases then it can be extremely difficult or even impossible to index the data. Whilst many indexing algorithms have made progress towards dealing with impurities, it remains a challenge.</p>
<p>In this work, we will train a neural network to: 1. Determine if a PXRD dataset was produced by a single or multiple phases 2. Determine <em>which peaks</em> in the diffraction pattern come from the minority phase(s) in the sample</p>
</section>
</section>
<section id="neural-network-architecture" class="level1">
<h1>Neural network architecture</h1>
<p>We will make use of the hybrid ConvNeXt-Transformer architecture we used in the last post. First, we’ll load the data as a pytorch Dataset object.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset, DataLoader</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="3">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DiffractionData(Dataset):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,base_name, root_dir<span class="op">=</span><span class="st">"./"</span>, idx<span class="op">=</span><span class="va">None</span>, dtype<span class="op">=</span>torch.float32):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> idx <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.crystal_system_numeric <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"crystal_systems_numeric.npy"</span>)[idx], dtype<span class="op">=</span>dtype)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hkl                    <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"hkl.npy"</span>)[idx], dtype<span class="op">=</span>dtype)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.intensities            <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"intensities.npy"</span>)[idx], dtype<span class="op">=</span>dtype)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.unit_cell              <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"unit_cell.npy"</span>)[idx], dtype<span class="op">=</span>dtype)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use extinctions rather than space groups</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.sg_number              <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"extinction_number.npy"</span>)[idx], dtype<span class="op">=</span>dtype)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.crystal_system_numeric <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"crystal_systems_numeric.npy"</span>), dtype<span class="op">=</span>dtype)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.hkl                    <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"hkl.npy"</span>), dtype<span class="op">=</span>dtype)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.intensities            <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"intensities.npy"</span>), dtype<span class="op">=</span>dtype)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.unit_cell              <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"unit_cell.npy"</span>), dtype<span class="op">=</span>dtype)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Use extinctions rather than space groups</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.sg_number              <span class="op">=</span> torch.tensor(np.load(root_dir<span class="op">+</span>base_name<span class="op">+</span><span class="st">"extinction_number.npy"</span>), dtype<span class="op">=</span>dtype)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.intensities)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.crystal_system_numeric[idx], <span class="va">self</span>.hkl[idx], <span class="va">self</span>.intensities[idx], <span class="va">self</span>.unit_cell[idx], <span class="va">self</span>.sg_number[idx]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>base_name <span class="op">=</span> <span class="st">"4-44-CuKa1-data_4000_"</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>root_dir <span class="op">=</span> <span class="st">"./"</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>dtype <span class="op">=</span> torch.float32</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Then we’ll define the data generation parameters</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> powcodgen <span class="im">import</span> patterns</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.auto <span class="im">import</span> tqdm</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Data generation parameters</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>ttmin <span class="op">=</span> <span class="dv">4</span>                       <span class="co"># Minimum data twotheta angle</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>ttmax <span class="op">=</span> <span class="dv">44</span>                      <span class="co"># Maximum data twotheta angle</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>peakrange <span class="op">=</span> <span class="fl">3.</span>                  <span class="co"># Buffer for peaks to move beyond the data range</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>datadim <span class="op">=</span> <span class="dv">2048</span>                  <span class="co"># Number of points in PXRD histograms</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>same_hwhm <span class="op">=</span> <span class="va">False</span>               <span class="co"># Impurity data has same peak shape &amp; hwhm as the dominant phase</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>min_impurity_intensity <span class="op">=</span> <span class="fl">0.02</span>   <span class="co"># Minimum intensity for impurity peaks</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>max_impurity_intensity <span class="op">=</span> <span class="fl">0.15</span>   <span class="co"># Maximum intensity for impurity peaks</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>add_background <span class="op">=</span> <span class="va">True</span>           <span class="co"># Include an amorphous background (Chebyshev)</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ------------------------------------------------------------</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the tensors used as the PXRD histograms</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>full_data <span class="op">=</span> torch.linspace(ttmin<span class="op">-</span>(peakrange<span class="op">/</span><span class="dv">2</span>), ttmax<span class="op">+</span>(peakrange<span class="op">/</span><span class="dv">2</span>),</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>                        <span class="bu">int</span>(np.ceil((ttmax<span class="op">-</span>ttmin<span class="op">+</span>peakrange)<span class="op">/</span>((ttmax<span class="op">-</span>ttmin)<span class="op">/</span>datadim))),</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                        device<span class="op">=</span>device, dtype<span class="op">=</span>dtype)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> (full_data[full_data <span class="op">&lt;=</span> ttmin<span class="op">+</span>(peakrange<span class="op">/</span><span class="dv">2</span>)]).clone() <span class="op">-</span> ttmin</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>plotdata <span class="op">=</span> full_data[(full_data <span class="op">&gt;=</span> ttmin) <span class="op">&amp;</span> (full_data <span class="op">&lt;=</span> ttmax)].cpu()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now we are ready to define the model, which will be effectively the same as the ConvNeXt Transformer we developed in the previous post.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ConvNeXt stuff</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GRN(nn.Module):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" Global Response Normalization, proposed in ConvNeXt v2 paper """</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, eps <span class="op">=</span> <span class="fl">1e-6</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.eps <span class="op">=</span> eps</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.gamma <span class="op">=</span> nn.Parameter(torch.zeros(<span class="dv">1</span>, dim, <span class="dv">1</span>))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.beta <span class="op">=</span> nn.Parameter(torch.zeros(<span class="dv">1</span>, dim, <span class="dv">1</span>))</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># x = (B, C, T)</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Want to average first over length (T), then divide by average channel (i.e. average of C)</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Divide the L2 norms by the average for each channel</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        Gx <span class="op">=</span> x.norm(p<span class="op">=</span><span class="dv">2</span>, dim<span class="op">=</span><span class="dv">2</span>, keepdim<span class="op">=</span><span class="va">True</span>) <span class="co"># (B, C, T) --&gt; (B, C, 1)</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        Nx <span class="op">=</span> Gx <span class="op">/</span> Gx.mean(dim<span class="op">=</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>).clamp(<span class="bu">min</span><span class="op">=</span><span class="va">self</span>.eps) <span class="co"># (B, C, 1) / (B, 1, 1) --&gt; (B, C, 1)</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.gamma <span class="op">*</span> (x <span class="op">*</span> Nx) <span class="op">+</span> <span class="va">self</span>.beta <span class="op">+</span> x</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DropPath(nn.Module):</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" DropPath regularisation can be used if needed, as described here:</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">    https://arxiv.org/abs/1605.07648v4</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, p: <span class="bu">float</span> <span class="op">=</span> <span class="fl">0.5</span>, inplace: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.p <span class="op">=</span> p</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.inplace <span class="op">=</span> inplace</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> drop_path(<span class="va">self</span>, x, keep_prob: <span class="bu">float</span> <span class="op">=</span> <span class="fl">1.0</span>, inplace: <span class="bu">bool</span> <span class="op">=</span> <span class="va">False</span>):</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        mask <span class="op">=</span> x.new_empty(x.shape[<span class="dv">0</span>], <span class="dv">1</span>, <span class="dv">1</span>).bernoulli_(keep_prob)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        mask.div_(keep_prob)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> inplace:</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>            x.mul_(mask)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> x <span class="op">*</span> mask</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.training <span class="kw">and</span> <span class="va">self</span>.p <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> <span class="va">self</span>.drop_path(x, <span class="va">self</span>.p, <span class="va">self</span>.inplace)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>):</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f"</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>__class__<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss">(p=</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>p<span class="sc">}</span><span class="ss">)"</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConvNeXtBlock(nn.Module):</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># A 1D ConvNeXt v2 block</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, drop_path_prob<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dwconv <span class="op">=</span> nn.Conv1d(in_channels<span class="op">=</span>dim, out_channels<span class="op">=</span>dim, kernel_size<span class="op">=</span><span class="dv">7</span>, groups<span class="op">=</span>dim, padding<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pwconv_1 <span class="op">=</span> nn.Conv1d(dim, <span class="dv">4</span><span class="op">*</span>dim, kernel_size<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act <span class="op">=</span> nn.GELU()</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.GRN <span class="op">=</span> GRN(<span class="dv">4</span><span class="op">*</span>dim)</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pwconv_2 <span class="op">=</span> nn.Conv1d(<span class="dv">4</span><span class="op">*</span>dim, dim, kernel_size<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.droppath <span class="op">=</span> DropPath(p<span class="op">=</span>drop_path_prob)</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, inputs):</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Inputs has shape (B, C, T)</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.dwconv(inputs)</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.norm(x.permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>))</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>) <span class="co"># Layernorm expects channels last</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pwconv_1(x)</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.act(x)</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.GRN(x)</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pwconv_2(x)</span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> inputs <span class="op">+</span> <span class="va">self</span>.droppath(x)</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> DownSample(nn.Module):</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_dim, out_dim):</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.norm <span class="op">=</span> nn.LayerNorm(in_dim)</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.down <span class="op">=</span> nn.Conv1d(in_dim, out_dim, kernel_size<span class="op">=</span><span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.norm(x.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)).permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.down(x)</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="34">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformer stuff</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GLU(nn.Module):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_dim, out_dim, act<span class="op">=</span>F.gelu, bias<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> nn.Linear(in_dim, out_dim, bias<span class="op">=</span>bias)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> nn.Linear(in_dim, out_dim, bias<span class="op">=</span>bias)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act <span class="op">=</span> act</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.act(<span class="va">self</span>.linear1(x))<span class="op">*</span><span class="va">self</span>.linear2(x)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TransformerBlock(nn.Module):</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim, heads, pos_length<span class="op">=</span><span class="dv">129</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.heads <span class="op">=</span> heads</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.qk <span class="op">=</span> nn.Linear(dim, <span class="dv">2</span><span class="op">*</span>dim)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.v <span class="op">=</span> nn.Linear(dim, dim)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mhsa_out <span class="op">=</span> nn.Linear(dim, dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.GLU <span class="op">=</span> GLU(dim, (dim<span class="op">*</span><span class="dv">3</span>)<span class="op">//</span><span class="dv">2</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear_out <span class="op">=</span> nn.Linear((dim<span class="op">*</span><span class="dv">3</span>)<span class="op">//</span><span class="dv">2</span>, dim, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln1 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ln2 <span class="op">=</span> nn.LayerNorm(dim)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pos <span class="op">=</span> nn.Embedding(pos_length, embedding_dim<span class="op">=</span>dim)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dropout <span class="op">=</span> nn.Dropout(dropout)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> mhsa(<span class="va">self</span>, x):</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        B, T, C <span class="op">=</span> x.shape</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        q, k <span class="op">=</span> <span class="va">self</span>.qk(x <span class="op">+</span> <span class="va">self</span>.pos(torch.arange(x.shape[<span class="dv">1</span>], device<span class="op">=</span>x.device))).chunk(<span class="dv">2</span>, dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> <span class="va">self</span>.v(x)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        q <span class="op">=</span> q.reshape(B, <span class="va">self</span>.heads, T, C<span class="op">//</span><span class="va">self</span>.heads)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> k.reshape(B, <span class="va">self</span>.heads, T, C<span class="op">//</span><span class="va">self</span>.heads)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.reshape(B, <span class="va">self</span>.heads, T, C<span class="op">//</span><span class="va">self</span>.heads)</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.scaled_dot_product_attention(q, k, v)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.reshape(B, T, C)</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.mhsa_out(x)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ffwd(<span class="va">self</span>, x):</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.GLU(x)</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear_out(<span class="va">self</span>.dropout(x))</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.mhsa(<span class="va">self</span>.ln1(x))</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.ffwd(<span class="va">self</span>.ln2(x))</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ConvNeXtTransformer(nn.Module):</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, datadim<span class="op">=</span><span class="dv">2048</span>, depths<span class="op">=</span>[<span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">2</span>], dims<span class="op">=</span>[<span class="dv">40</span>, <span class="dv">80</span>, <span class="dv">160</span>, <span class="dv">320</span>],</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                 transformer_layers<span class="op">=</span><span class="dv">6</span>, attention_heads<span class="op">=</span><span class="dv">2</span>, drop_path_prob<span class="op">=</span><span class="fl">0.1</span>, dropout<span class="op">=</span><span class="fl">0.1</span>):</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.depths <span class="op">=</span> depths</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.datadim <span class="op">=</span> datadim</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.downsample_layers <span class="op">=</span> nn.ModuleList() <span class="co"># stem and 3 intermediate downsampling conv layers</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initial_conv <span class="op">=</span> nn.Conv1d(<span class="dv">1</span>, dims[<span class="dv">0</span>], kernel_size<span class="op">=</span><span class="dv">7</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.initial_norm <span class="op">=</span> nn.LayerNorm(dims[<span class="dv">0</span>])</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_layers <span class="op">=</span> nn.ModuleList()</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transformer_layers <span class="op">=</span> nn.ModuleList()</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cls_token <span class="op">=</span> nn.Embedding(<span class="dv">1</span>, dims[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, dd <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(depths, dims)):</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>            depth, dim <span class="op">=</span> dd</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> d <span class="kw">in</span> <span class="bu">range</span>(depth):</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.conv_layers.append(ConvNeXtBlock(dim, drop_path_prob<span class="op">=</span>drop_path_prob))</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i<span class="op">+</span><span class="dv">1</span> <span class="op">!=</span> <span class="bu">len</span>(dims):</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.conv_layers.append(DownSample(in_dim<span class="op">=</span>dim, out_dim<span class="op">=</span>dims[i<span class="op">+</span><span class="dv">1</span>]))</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(transformer_layers):</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.transformer_layers.append(TransformerBlock(dims[<span class="op">-</span><span class="dv">1</span>], attention_heads, dropout<span class="op">=</span>dropout))</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_norm <span class="op">=</span> nn.LayerNorm(dims[<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output_pure_impure <span class="op">=</span> nn.Sequential(</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>            GLU(dims[<span class="op">-</span><span class="dv">1</span>], <span class="dv">32</span>),</span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">32</span>, <span class="dv">1</span>)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patch_classifier <span class="op">=</span> nn.Conv1d(dims[<span class="op">-</span><span class="dv">1</span>], <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, shapes<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.initial_conv(x)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.initial_norm(x.permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>)).permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> shapes:</span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(x.shape)</span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.conv_layers:</span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> l(x)</span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> shapes:</span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(x.shape)</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> F.gelu(x)</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Now concatenate the CLS token with the output of the convolutional layers</span></span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>        cls <span class="op">=</span> <span class="va">self</span>.cls_token(torch.arange(<span class="dv">1</span>, device<span class="op">=</span>x.device)).squeeze().expand(x.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>).unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.cat([cls, x], dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> l <span class="kw">in</span> <span class="va">self</span>.transformer_layers:</span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>            x <span class="op">=</span> l(x)</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> shapes:</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(x.shape)</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.final_norm(x).permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> shapes:</span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(x.shape)</span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>        x_pure_impure <span class="op">=</span> <span class="va">self</span>.output_pure_impure(x[:,:,<span class="dv">0</span>])</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a>        patch_pure_impure <span class="op">=</span> <span class="va">self</span>.patch_classifier(x[:,:,<span class="dv">1</span>:])</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a>        B, T, C <span class="op">=</span> patch_pure_impure.shape</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a>        patch_pure_impure <span class="op">=</span> patch_pure_impure.permute(<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">1</span>).reshape(B, T<span class="op">*</span>C)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> shapes:</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(x_pure_impure.shape, patch_pure_impure.shape)</span>
<span id="cb5-103"><a href="#cb5-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x_pure_impure, patch_pure_impure</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="7">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_stats(outputs, ground_truth):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> (torch.sigmoid(outputs) <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">type</span>(torch.<span class="bu">int</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        TP <span class="op">=</span> ((ground_truth <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (pred <span class="op">==</span> <span class="dv">1</span>)).<span class="bu">sum</span>()</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        FP <span class="op">=</span> ((ground_truth <span class="op">==</span> <span class="dv">0</span>) <span class="op">&amp;</span> (pred <span class="op">==</span> <span class="dv">1</span>)).<span class="bu">sum</span>()</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        TN <span class="op">=</span> ((ground_truth <span class="op">==</span> <span class="dv">0</span>) <span class="op">&amp;</span> (pred <span class="op">==</span> <span class="dv">0</span>)).<span class="bu">sum</span>()</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        FN <span class="op">=</span> ((ground_truth <span class="op">==</span> <span class="dv">1</span>) <span class="op">&amp;</span> (pred <span class="op">==</span> <span class="dv">0</span>)).<span class="bu">sum</span>()</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        precision <span class="op">=</span> torch.nan_to_num(TP<span class="op">/</span>(TP<span class="op">+</span>FP))</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        recall <span class="op">=</span> torch.nan_to_num(TP<span class="op">/</span>(TP<span class="op">+</span>FN))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        f1 <span class="op">=</span> torch.nan_to_num(<span class="fl">2.</span><span class="op">*</span>(precision<span class="op">*</span>recall)<span class="op">/</span>(precision<span class="op">+</span>recall))</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        accuracy <span class="op">=</span> torch.nan_to_num((TP<span class="op">+</span>TN)<span class="op">/</span>(TP<span class="op">+</span>TN<span class="op">+</span>FP<span class="op">+</span>FN))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        mcc <span class="op">=</span> torch.nan_to_num(((TP<span class="op">*</span>TN) <span class="op">-</span> (FP<span class="op">*</span>FN)) <span class="op">/</span> torch.sqrt((TP<span class="op">+</span>FP)<span class="op">*</span>(TP<span class="op">+</span>FN)<span class="op">*</span>(TN<span class="op">+</span>FP)<span class="op">*</span>(TN<span class="op">+</span>FN)))</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> precision, recall, f1, accuracy, mcc</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_lr(it):</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Taken from https://github.com/karpathy/nanoGPT/blob/master/train.py</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 1) linear warmup for warmup_iters steps</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">&lt;</span> warmup_iters:</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> learning_rate <span class="op">*</span> it <span class="op">/</span> warmup_iters</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 2) if it &gt; lr_decay_iters, return min learning rate</span></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> it <span class="op">&gt;</span> lr_decay_iters:</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> min_lr</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 3) in between, use cosine decay down to min learning rate</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    decay_ratio <span class="op">=</span> (it <span class="op">-</span> warmup_iters) <span class="op">/</span> (lr_decay_iters <span class="op">-</span> warmup_iters)</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="dv">0</span> <span class="op">&lt;=</span> decay_ratio <span class="op">&lt;=</span> <span class="dv">1</span></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    coeff <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> (<span class="fl">1.0</span> <span class="op">+</span> math.cos(math.pi <span class="op">*</span> decay_ratio)) <span class="co"># coeff ranges 0..1</span></span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> min_lr <span class="op">+</span> coeff <span class="op">*</span> (learning_rate <span class="op">-</span> min_lr)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Training / validation code</span></span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_loss(iter_num, dataloader, model, optimizer, epoch,</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>            train<span class="op">=</span><span class="va">True</span>, show_pbar<span class="op">=</span><span class="va">True</span>, impure_peak_threshold<span class="op">=</span><span class="fl">2.5e-2</span>,</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>            plot<span class="op">=</span><span class="va">True</span>, decay_lr<span class="op">=</span><span class="va">True</span>, learning_rate<span class="op">=</span><span class="fl">1e-3</span>):</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a><span class="co">    Get the losses for an epoch. Toggle between the dataloaders so the same code can be recycled</span></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a><span class="co">    for the training and validation sets.</span></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_pbar:</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        pbar <span class="op">=</span> tqdm(dataloader)</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        pbar <span class="op">=</span> dataloader</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>    logs <span class="op">=</span> []</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> train:</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_cs, batch_hkl, batch_i, batch_cell, batch_sg_number <span class="kw">in</span> pbar:</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>        <span class="co"># zero the parameter gradients</span></span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>        optimizer.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># forward + backward + optimize</span></span>
<span id="cb6-51"><a href="#cb6-51" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(batch_cs) <span class="op">%</span> <span class="dv">2</span> <span class="op">!=</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(batch_cs) <span class="op">%</span> <span class="dv">3</span> <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb6-52"><a href="#cb6-52" aria-hidden="true" tabindex="-1"></a>            maxlength <span class="op">=</span> <span class="dv">6</span><span class="op">*</span>(batch_cs.shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">6</span>)</span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a>            batch_cs <span class="op">=</span> batch_cs[:maxlength]</span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a>            batch_hkl <span class="op">=</span> batch_hkl[:maxlength]</span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a>            batch_i <span class="op">=</span> batch_i[:maxlength]</span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a>            batch_cell <span class="op">=</span> batch_cell[:maxlength]</span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a>            batch_sg_number <span class="op">=</span> batch_sg_number[:maxlength]</span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a>        calcdata <span class="op">=</span> patterns.calculate_diffraction_patterns_with_impurities(</span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a>                                        x,</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a>                                        full_data,</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a>                                        batch_cs.to(device),</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a>                                        batch_hkl.to(device),</span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a>                                        batch_i.to(device),</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a>                                        batch_cell.to(device),</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a>                                        batch_sg_number.to(device),</span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a>                                        same_hwhm<span class="op">=</span>same_hwhm,</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a>                                        min_impurity_intensity<span class="op">=</span>min_impurity_intensity,</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a>                                        max_impurity_intensity<span class="op">=</span>max_impurity_intensity,</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a>                                        add_background <span class="op">=</span> add_background,</span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a>        combined, pure_patterns, impure_patterns, pure_impure, cs, cell, sgs, hkls <span class="op">=</span> calcdata</span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a>        pred_pure, pred_peaks <span class="op">=</span> model(combined.unsqueeze(<span class="dv">1</span>))</span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a>        impurepeaks <span class="op">=</span> ((impure_patterns <span class="op">-</span> pure_patterns) <span class="op">&gt;</span> impure_peak_threshold).<span class="bu">type</span>(dtype)</span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a>        pure_impure_bce <span class="op">=</span> F.binary_cross_entropy_with_logits(pred_pure.squeeze(), pure_impure)</span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a>        pred_peaks_bce <span class="op">=</span> F.binary_cross_entropy_with_logits(pred_peaks.squeeze(), impurepeaks)</span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>        <span class="co"># precision, recall, f1, accuracy, mcc</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>        p_i_stats <span class="op">=</span> get_stats(pred_pure.squeeze(), pure_impure)</span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>        patch_stats <span class="op">=</span> get_stats(pred_peaks.squeeze(), impurepeaks)</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>        loss <span class="op">=</span> pure_impure_bce <span class="op">+</span> pred_peaks_bce</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> train:</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>            <span class="co"># determine and set the learning rate for this iteration</span></span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>            lr <span class="op">=</span> get_lr(iter_num) <span class="cf">if</span> decay_lr <span class="cf">else</span> learning_rate</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> param_group <span class="kw">in</span> optimizer.param_groups:</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>                param_group[<span class="st">'lr'</span>] <span class="op">=</span> lr</span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a>            iter_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>            nn.utils.clip_grad_norm_(model.parameters(), grad_clip)</span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> show_pbar:</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>            pbar.set_description_str(<span class="ss">f"Epoch: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss"> P/I Prec </span><span class="sc">{</span>p_i_stats[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss"> P/I Rec </span><span class="sc">{</span>p_i_stats[<span class="dv">1</span>]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss"> Patch Prec </span><span class="sc">{</span>patch_stats[<span class="dv">0</span>]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss"> Patch Rec </span><span class="sc">{</span>patch_stats[<span class="dv">1</span>]<span class="sc">.</span>item()<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>        logs.append(torch.tensor([p_i_stats <span class="op">+</span> patch_stats]))</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> train:</span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> plot:</span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>                plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>                plt.plot([<span class="dv">4</span>, <span class="dv">44</span>],[<span class="fl">0.5</span>,<span class="fl">0.5</span>], c<span class="op">=</span><span class="st">"k"</span>, alpha<span class="op">=</span><span class="fl">0.15</span>)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a>                plt.plot(plotdata, combined[i].cpu())</span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a>                plt.plot(plotdata, <span class="op">-</span><span class="dv">1</span><span class="op">*</span>impure_patterns[i].cpu())</span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a>                plt.plot(plotdata, F.sigmoid(pred_peaks[i]).detach().cpu(), alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a>                plt.plot(plotdata, impurepeaks[i].cpu(), alpha<span class="op">=</span><span class="fl">0.2</span>, c<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>                plt.title(<span class="ss">f"</span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>F<span class="sc">.</span>sigmoid(pred_pure[i])<span class="sc">.</span>detach()<span class="sc">.</span>item()<span class="sc">:.2f}</span><span class="ss"> %"</span>)</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>                plt.show()</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> iter_num, logs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Set up the training data and associated variables</p>
<div class="cell" data-execution_count="8">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>batchsize <span class="op">=</span> (<span class="dv">128</span><span class="op">*</span><span class="dv">3</span>)<span class="op">//</span><span class="dv">2</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> DiffractionData(base_name, root_dir<span class="op">=</span>root_dir)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator().manual_seed(<span class="dv">42</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>train_set, val_set <span class="op">=</span> torch.utils.data.random_split(dataset, [<span class="fl">0.8</span>, <span class="fl">0.2</span>], g)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> DataLoader(train_set, batch_size<span class="op">=</span>batchsize, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>val_dataloader   <span class="op">=</span> DataLoader(val_set,   batch_size<span class="op">=</span>batchsize, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training samples = </span><span class="sc">{</span><span class="bu">len</span>(train_set)<span class="sc">}</span><span class="ch">\n</span><span class="ss">Validation samples = </span><span class="sc">{</span><span class="bu">len</span>(val_set)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Training samples = 230499
Validation samples = 57624</code></pre>
</div>
</div>
<p>Now let’s initialise the the model and optimizer. Rather than do extensive hyperparameter optimisation, I’ve just taken the hyperparameters for the optimiser used by <a href="https://twitter.com/karpathy">Andrej Karpathy</a> for his excellent nanoGPT model, which can be found <a href="https://github.com/karpathy/nanoGPT/blob/master/train.py">here</a>.</p>
<div class="cell" data-execution_count="9">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">6e-4</span> <span class="co"># max learning rate</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>max_iters <span class="op">=</span> (<span class="bu">len</span>(train_set)<span class="op">//</span>batchsize) <span class="op">*</span> num_epochs</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Epochs: </span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss"> Total gradient updates: </span><span class="sc">{</span>max_iters<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">1e-1</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>beta1 <span class="op">=</span> <span class="fl">0.9</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>beta2 <span class="op">=</span> <span class="fl">0.95</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>grad_clip <span class="op">=</span> <span class="fl">1.0</span> <span class="co"># clip gradients at this value</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>decay_lr <span class="op">=</span> <span class="va">True</span> <span class="co"># whether to decay the learning rate</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>warmup_iters <span class="op">=</span> <span class="dv">2000</span> <span class="co"># how many steps to warm up for</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>lr_decay_iters <span class="op">=</span> max_iters</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>min_lr <span class="op">=</span> <span class="fl">6e-5</span> <span class="co"># minimum learning rate, should be ~= learning_rate/10</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>impure_peak_threshold <span class="op">=</span> <span class="fl">5e-3</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ConvNeXtTransformer(depths<span class="op">=</span>[<span class="dv">2</span>,<span class="dv">2</span>,<span class="dv">6</span>,<span class="dv">2</span>],</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>                            dims<span class="op">=</span>[<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">16</span>,<span class="dv">32</span>],</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>                            transformer_layers<span class="op">=</span><span class="dv">8</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>                            attention_heads<span class="op">=</span><span class="dv">4</span>,</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>                            drop_path_prob<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>                            dropout<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>                        ).to(device)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model parameters:"</span>,<span class="bu">sum</span>(p.numel() <span class="cf">for</span> p <span class="kw">in</span> model.parameters() <span class="cf">if</span> p.requires_grad))</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.AdamW(params<span class="op">=</span>model.parameters(), lr<span class="op">=</span>learning_rate, betas<span class="op">=</span>(beta1, beta2), weight_decay<span class="op">=</span>weight_decay)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Epochs: 50 Total gradient updates: 60000
Model parameters: 146257</code></pre>
</div>
</div>
<p>Let’s set this thing training!</p>
<div class="cell">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>show_pbar <span class="op">=</span> <span class="va">False</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>all_train_metrics <span class="op">=</span> []</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>all_val_metrics <span class="op">=</span> []</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>best_val_mape <span class="op">=</span> <span class="bu">float</span>(<span class="st">"inf"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>iter_num <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    iter_num, train_metrics <span class="op">=</span> get_loss(iter_num, train_dataloader, model, optimizer, epoch, train<span class="op">=</span><span class="va">True</span>, show_pbar<span class="op">=</span>show_pbar, impure_peak_threshold<span class="op">=</span>impure_peak_threshold)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    all_train_metrics.append(train_metrics)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    train_metrics <span class="op">=</span> torch.cat(train_metrics, dim<span class="op">=</span><span class="dv">0</span>).mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    _, val_metrics <span class="op">=</span> get_loss(iter_num, val_dataloader, model, optimizer, epoch, train<span class="op">=</span><span class="va">False</span>, show_pbar<span class="op">=</span>show_pbar, impure_peak_threshold<span class="op">=</span>impure_peak_threshold, plot<span class="op">=</span>show_pbar)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    all_val_metrics.append(val_metrics)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    val_metrics <span class="op">=</span> torch.cat(val_metrics, dim<span class="op">=</span><span class="dv">0</span>).mean(dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_pbar:</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Best Val Pure / Impure classification:"</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Precision: </span><span class="sc">{</span>val_metrics[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss"> Recall: </span><span class="sc">{</span>val_metrics[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss"> F1: </span><span class="sc">{</span>val_metrics[<span class="dv">2</span>]<span class="sc">:.3f}</span><span class="ss"> Accuracy: </span><span class="sc">{</span>val_metrics[<span class="dv">3</span>]<span class="sc">:.3f}</span><span class="ss"> MCC </span><span class="sc">{</span>val_metrics[<span class="dv">4</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Val - Peak level classification:"</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Precision: </span><span class="sc">{</span>val_metrics[<span class="dv">5</span>]<span class="sc">:.3f}</span><span class="ss"> Recall: </span><span class="sc">{</span>val_metrics[<span class="dv">6</span>]<span class="sc">:.3f}</span><span class="ss"> F1: </span><span class="sc">{</span>val_metrics[<span class="dv">7</span>]<span class="sc">:.3f}</span><span class="ss"> Accuracy: </span><span class="sc">{</span>val_metrics[<span class="dv">8</span>]<span class="sc">:.3f}</span><span class="ss"> MCC </span><span class="sc">{</span>val_metrics[<span class="dv">9</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the model</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>torch.save({<span class="st">'epoch'</span>: epoch,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'model_state_dict'</span>: model.state_dict(),</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'optimizer_state_dict'</span>: optimizer.state_dict(),</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        }, <span class="st">"saved_models/Impurity_detection_ConvNeXt_Transformer.pth"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The model took about 3 hours to train on my RTX 2060 GPU, with a modest batch size and 60k gradient updates. Let’s plot the model performance over time, and see how well it performed in terms of some commonly used metrics for binary classification tasks: - <a href="https://en.wikipedia.org/wiki/Precision_and_recall">Precision and Recall</a> - <a href="https://en.wikipedia.org/wiki/F-score">F1 (harmonic mean of Precision and Recall)</a> - <a href="https://en.wikipedia.org/wiki/Accuracy_and_precision#In_binary_classification">Accuracy</a> - <a href="https://en.wikipedia.org/wiki/Phi_coefficient">Matthews Correlation Coefficient (MCC)</a></p>
<div class="cell" data-execution_count="38">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the average loss for each epoch and plot</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train_av <span class="op">=</span> torch.cat([x.mean(dim<span class="op">=</span><span class="dv">0</span>,keepdim<span class="op">=</span><span class="va">True</span>) <span class="cf">for</span> x <span class="kw">in</span> [torch.cat(y, dim<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> y <span class="kw">in</span> all_train_metrics]], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>val_av <span class="op">=</span> torch.cat([x.mean(dim<span class="op">=</span><span class="dv">0</span>,keepdim<span class="op">=</span><span class="va">True</span>) <span class="cf">for</span> x <span class="kw">in</span> [torch.cat(y, dim<span class="op">=</span><span class="dv">0</span>) <span class="cf">for</span> y <span class="kw">in</span> all_val_metrics]], dim<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, info <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">"Pure / Impure classification"</span>, <span class="st">"Peak-level classification"</span>]):</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">5</span>, nrows<span class="op">=</span><span class="dv">1</span>, figsize<span class="op">=</span>(<span class="dv">17</span>,<span class="fl">3.5</span>))</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    fig.suptitle(info)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j, metric <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">"Precision"</span>, <span class="st">"Recall"</span>, <span class="st">"F1"</span>, <span class="st">"Accuracy"</span>, <span class="st">"MCC"</span>]):</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        ax[j].plot(train_av[:,i<span class="op">*</span><span class="dv">5</span><span class="op">+</span>j])</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        ax[j].plot(val_av[:,i<span class="op">*</span><span class="dv">5</span><span class="op">+</span>j])</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>        ax[j].set_title(metric)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> j <span class="op">==</span> <span class="dv">2</span>:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            ax[j].set_xlabel(<span class="st">"Epoch"</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    ax[j].legend([<span class="st">"Train"</span>,<span class="st">"Val"</span>])</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>val_av_max <span class="op">=</span> val_av.<span class="bu">max</span>(dim<span class="op">=</span><span class="dv">0</span>).values</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Val Pure / Impure classification:"</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Precision: </span><span class="sc">{</span>val_av_max[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss"> Recall: </span><span class="sc">{</span>val_av_max[<span class="dv">1</span>]<span class="sc">:.3f}</span><span class="ss"> F1: </span><span class="sc">{</span>val_av_max[<span class="dv">2</span>]<span class="sc">:.3f}</span><span class="ss"> Accuracy: </span><span class="sc">{</span>val_av_max[<span class="dv">3</span>]<span class="sc">:.3f}</span><span class="ss"> MCC </span><span class="sc">{</span>val_av_max[<span class="dv">4</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Best Val Peak-level classification:"</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Precision: </span><span class="sc">{</span>val_av_max[<span class="dv">5</span>]<span class="sc">:.3f}</span><span class="ss"> Recall: </span><span class="sc">{</span>val_av_max[<span class="dv">6</span>]<span class="sc">:.3f}</span><span class="ss"> F1: </span><span class="sc">{</span>val_av_max[<span class="dv">7</span>]<span class="sc">:.3f}</span><span class="ss"> Accuracy: </span><span class="sc">{</span>val_av_max[<span class="dv">8</span>]<span class="sc">:.3f}</span><span class="ss"> MCC </span><span class="sc">{</span>val_av_max[<span class="dv">9</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-11-output-1.png" class="quarto-discovered-preview-image img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-11-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Best Val Pure / Impure classification:
  Precision: 0.943 Recall: 0.890 F1: 0.892 Accuracy: 0.895 MCC 0.794

Best Val Peak-level classification:
  Precision: 0.774 Recall: 0.408 F1: 0.511 Accuracy: 0.982 MCC 0.522</code></pre>
</div>
</div>
<p>Unsurprisingly, the performance of the model on the pure vs impure classification task is generally higher than that of the peak level classification task, where the model is trying to determine <em>which peaks</em> in the data come from the minority phase. This is most clearly seen in the case of the recall, where the model is only able to catch about 40 % of the impurity phase peaks. However, we still see pretty good performance on this challenging task with a very small model!</p>
<p>The accuracy for the peak-level classification task is somewhat misleading. This is readily explained by the fact that the data are very imbalanced for this task, the vast majority of points on the PXRD histogram not being associated with any impurity phase peaks.</p>
<p>Let’s now take a look at the information the model gives us, and check that the performance implied by these metrics is actually borne out in practice, and more importantly, if this model will actually be useful in the real world when trying to index a PXRD dataset.</p>
<div class="cell" data-execution_count="43">
<details>
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_plots(dataloader, model, impure_peak_threshold<span class="op">=</span><span class="fl">5e-3</span>, number_of_plots<span class="op">=</span><span class="dv">5</span>):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Get the losses for an epoch. Toggle between the dataloaders so the same code can be recycled</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">    for the training and validation sets.</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch_cs, batch_hkl, batch_i, batch_cell, batch_sg_number <span class="kw">in</span> dataloader:</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(batch_cs) <span class="op">%</span> <span class="dv">2</span> <span class="op">!=</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(batch_cs) <span class="op">%</span> <span class="dv">3</span> <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            maxlength <span class="op">=</span> <span class="dv">6</span><span class="op">*</span>(batch_cs.shape[<span class="dv">0</span>]<span class="op">//</span><span class="dv">6</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>            batch_cs <span class="op">=</span> batch_cs[:maxlength]</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>            batch_hkl <span class="op">=</span> batch_hkl[:maxlength]</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>            batch_i <span class="op">=</span> batch_i[:maxlength]</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>            batch_cell <span class="op">=</span> batch_cell[:maxlength]</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>            batch_sg_number <span class="op">=</span> batch_sg_number[:maxlength]</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>        calcdata <span class="op">=</span> patterns.calculate_diffraction_patterns_with_impurities(</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>                                        x,</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>                                        full_data,</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>                                        batch_cs.to(device),</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>                                        batch_hkl.to(device),</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>                                        batch_i.to(device),</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                                        batch_cell.to(device),</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                                        batch_sg_number.to(device),</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>                                        same_hwhm<span class="op">=</span>same_hwhm,</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>                                        min_impurity_intensity<span class="op">=</span>min_impurity_intensity,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>                                        max_impurity_intensity<span class="op">=</span>max_impurity_intensity,</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>                                        add_background <span class="op">=</span> add_background,</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>                                    )</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>        combined, pure_patterns, impure_patterns, pure_impure, cs, cell, sgs, hkls <span class="op">=</span> calcdata</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>        pred_pure, pred_peaks <span class="op">=</span> model(combined.unsqueeze(<span class="dv">1</span>))</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>        impurepeaks <span class="op">=</span> ((impure_patterns <span class="op">-</span> pure_patterns) <span class="op">&gt;</span> impure_peak_threshold).<span class="bu">type</span>(dtype)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(number_of_plots):</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>            plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>,<span class="dv">4</span>))</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>            plt.plot([<span class="dv">4</span>, <span class="dv">44</span>],[<span class="fl">0.5</span>,<span class="fl">0.5</span>], c<span class="op">=</span><span class="st">"k"</span>, alpha<span class="op">=</span><span class="fl">0.15</span>)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>            plt.plot(plotdata, combined[i].cpu())</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>            plt.plot(plotdata, <span class="op">-</span><span class="dv">1</span><span class="op">*</span>impure_patterns[i].cpu())</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>            plt.plot(plotdata, F.sigmoid(pred_peaks[i]).detach().cpu(), alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>            plt.plot(plotdata, impurepeaks[i].cpu(), alpha<span class="op">=</span><span class="fl">0.2</span>, c<span class="op">=</span><span class="st">"k"</span>)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>            plt.xlabel(<span class="st">"$2</span><span class="ch">\\</span><span class="st">theta$"</span>)</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>            plt.title(<span class="ss">f"Probability of impure data: </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>F<span class="sc">.</span>sigmoid(pred_pure[i])<span class="sc">.</span>detach()<span class="sc">.</span>item()<span class="sc">:.2f}</span><span class="ss"> %"</span>)</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>            plt.xlim([<span class="dv">4</span>, <span class="dv">44</span>])</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>            plt.show()</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>get_plots(val_dataloader, model, number_of_plots<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-12-output-1.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-12-output-2.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-12-output-3.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-12-output-4.png" class="img-fluid"></p>
</div>
<div class="cell-output cell-output-display">
<p><img src="2024-02-17-Detecting-impurities-in-PXRD-data_files/figure-html/cell-12-output-5.png" class="img-fluid"></p>
</div>
</div>
<p>There’s quite a lot going on in these plots, so let’s break down what they show: 1. The title of the plot indicates the results of the binary pure / impure task. Anything over 50 % is considered to be a positive identification of a multi-phase dataset. The higher the number, the greater the probability assigned by the model. 2. The grey line at y=0.5 is just there to give a visual indication of when the model is predicting that a given peak comes from an impurity phase. Anything below this threshold is not considered a positive identification (though may still be of interest!) 3. The blue line is the data that was fed into the model - this is synthetic data, which may or may not contain peaks from multiple phases 4. The orange line is the ground-truth intensities for any impurity phase present in the data, reflected by the x-axis. This allows us to see if the input data did indeed contain impurities, and if so, where the peaks from the impurity phase should be most prominent. 5. The green line is the model’s prediction, for each point in the histogram, for if the intensity at this point can be mostly attributed to an impurity phase (after correcting for background scattering etc) 6. The pale grey lines are the ground-truth labels that the model was trained to predict. In an ideal case, the green line should completely overlap with these grey lines.</p>
<p>As we can see from the plots, the model does pretty well! In each of the examples plotted above, it correctly determined if the data came from a single phase or multiple phases. In terms of the peak-level classification task, we can see that the model, where impurity peaks are present, does pretty well at picking up peaks early in the data, but less well further on in the pattern. This isn’t too surprising due to several factors, such as the atomic form-factor fall off leading to lower intensities and the greater density of peaks leading to increased likelihood of peak overlap.</p>
<p>All in all, this looks like it could provide some useful information to end users if they are struggling to index a PXRD dataset. One possible cause of a failure to index the data could be the present of impurity peaks. If these can be eliminated from the indexing attempt, then it may become possible to index the data!</p>
</section>
<section id="web-app" class="level1">
<h1>Web-App</h1>
<p>I’ve made the model weights available <a href="https://github.com/mspillman/impurities">here</a>. However, not everyone will want to run a python script every time they want to check a dataset, so I thought I’d also write a simple web-app and make it freely available and accessible to users.</p>
<p>The web-app can be found <a href="https://impuritydetector.streamlit.app/">here</a>, and it’s operation is described below.</p>
<section id="how-it-works" class="level2">
<h2 class="anchored" data-anchor-id="how-it-works">How it works</h2>
<p>The model was trained on data designed to approximate patterns collected on laboratory-based instruments using Cu Ka1 radiation, with a step size of 0.019 degrees and a range of 4 - 44 degrees <span class="math inline">\(2\theta\)</span>. Any data that does not meet these parameters clearly will need modification before it can be used by the model.</p>
<p>Any data collected with a different wavelength and/or step size will automatically be converted to the expected pattern for CuKa1 with the correct step size via interpolation. Any data below or above the expected range is trimmed. If the data range starts <em>after</em> 4 degrees <span class="math inline">\(2\theta\)</span>, then the first datapoint is used to fill in the blanks. This is an augmentation that was included in the data-generation code, and as such, the model should correctly ignore this.</p>
<p>Once the diffraction data is in the correct format for the model, the model is used to determine: 1. The probability that the pattern was produced by a single or multiple crystalline phases. The prediction is printed above the plot 2. An interactive plot showing the diffraction data, overlaid with the probability assigned by the model to each point on the histogram that the intensity (after accounting for the background) can be accounted for by an impurity phase.</p>
<p>Let’s see if the web-app may actually be useful for end users. In <a href="https://pubs.rsc.org/en/content/articlelanding/2011/ce/c1ce05650f">this publication</a>, we reported the crystal structure of a co-crystal that was produced by grinding carbamazepine and indomethacin together. The structure was solved from PXRD data, relatively easily. However, the hardest part of the solution process was actually indexing the data - this was due to the presence of left-over carbamazepine and indomethacin within the polycrystalline sample that resulted.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/CBZ-IND.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Majumder et al, 2011</figcaption><p></p>
</figure>
</div>
<p>Below is a screenshot showing the output of the model on the experimental data we collected on the cocrystal.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/impurity-web-app-screenshot.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Web-app example output</figcaption><p></p>
</figure>
</div>
<p>As we can see, the model correctly predicts that the data contains peaks from multiple phases, with a high degree of confidence. Let’s zoom in on the data and see which peaks are predicted to come from the impurities:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/cbz-ind-web-app-zoom.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Web app zoomed in</figcaption><p></p>
</figure>
</div>
<p>Anything over 0.5 is a positive prediction, so it looks like the peaks at ca. 10.2, 11.6, 13.1 and 17.2 should be treated as impurity peaks. There are several other peaks, which the model finds suspicious, though that don’t meet the 0.5 probability threshold. Let’s take a look at anything for which the model gives &gt;0.3 probability of being an impurity peak as “suspicious”, and check the results in the table below:</p>
<table class="table">
<colgroup>
<col style="width: 28%">
<col style="width: 29%">
<col style="width: 22%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th>Peak <span class="math inline">\(2\theta\)</span> position / <span class="math inline">\(^{o}\)</span></th>
<th>Probability of impurity</th>
<th>Is impurity line?</th>
<th>Model correct?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>9.0</td>
<td>0.39</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr class="even">
<td>9.5</td>
<td>0.31</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr class="odd">
<td>10.2</td>
<td>0.53</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="even">
<td>11.6</td>
<td>0.57</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="odd">
<td>12.1</td>
<td>0.47</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr class="even">
<td>13.1</td>
<td>0.64</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="odd">
<td>15.3</td>
<td>0.45</td>
<td>✓</td>
<td>✗</td>
</tr>
<tr class="even">
<td>16.7</td>
<td>0.38</td>
<td>✓</td>
<td>✗</td>
</tr>
<tr class="odd">
<td>17.1</td>
<td>0.40</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr class="even">
<td>17.3</td>
<td>0.54</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr class="odd">
<td>21.0</td>
<td>0.47</td>
<td>✗</td>
<td>✓</td>
</tr>
<tr class="even">
<td>22.4</td>
<td>0.31</td>
<td>✗</td>
<td>✓</td>
</tr>
</tbody>
</table>
<p>I mark the model as being correct if the line is an impurity line, and it assigns &gt; 0.5 probability, or the line is not an impurity line and it assigns &lt; 0.5 probability. Otherwise, it is marked as being incorrect.</p>
<p>As we can see from the results, the model gets the majority of the assignments correct which is great! It also gives a bit of a “jumping off” point for the end user to look more closely at particular lines in the data, which may help to identify the impurities.</p>
<p>As part of the solution process for the paper I linked above, we ended up using TOPAS to extract the “pure phase” data for the cocrystal. If I pass this data through the model, we can clearly see that the model correctly recognizes that the data are pure and there aren’t any suspicious peaks!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/pure-coxtal.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Pure cocrystal phase data</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="conclusions" class="level1">
<h1>Conclusions</h1>
<p>In this post, we’ve developed a hybrid convolutional transformer model that can relatively reliably detect multi-phase PXRD data. This may be of interest to crystallographers who have patterns that are proving challenging to index!</p>
<p>The web-app described in the latter part of the post is freely available here - <a href="https://impuritydetector.streamlit.app/">https://impuritydetector.streamlit.app/</a></p>
<p>The code for the web app and the pre-trained model is available here - <a href="https://github.com/mspillman/impurities">https://github.com/mspillman/impurities</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>
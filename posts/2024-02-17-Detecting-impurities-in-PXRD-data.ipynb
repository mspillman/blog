{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Detecting Impurities in PXRD data\"\n",
    "format:\n",
    "  html:\n",
    "    code-overflow: scroll\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "author: Mark Spillman\n",
    "categories:\n",
    "- PXRD\n",
    "- Machine learning\n",
    "- Synthetic data\n",
    "- Impurities\n",
    "date: '2024-02-17'\n",
    "description: Using convolutional transformer encoders to detect multi-phase PXRD patterns\n",
    "image: images/MAPE.png\n",
    "toc: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In my [previous post - UPDATED LINK NEEDED](), I replicated the results of an article by [Chitturi and coworkers - LINK NEEDED](), who showed that convolutional neural networks can be used to determine unit cell edge lengths directly from PXRD data with a relatively good level of precision. I was able to both improve on their results and reduce the parameter count of the neural network by updating the architecture used.\n",
    "\n",
    "In this post, we'll look at an application of neural networks that I've not yet seen in the literature.\n",
    "\n",
    "## Impurities and Indexing\n",
    "\n",
    "One thing that can severely hamper our ability to index a powder diffraction pattern is the presence of peaks coming from minority (i.e. impurity) phases in the sample. If the sample contains multiple crystalline phases then it can be extremely difficult or even impossible to index the data. Whilst many indexing algorithms have made progress towards dealing with impurities, it remains a challenge.\n",
    "\n",
    "In this work, we will train a neural network to:\n",
    "1. Determine if a PXRD dataset was produced by a single or multiple phases\n",
    "2. Determine _which peaks_ in the diffraction pattern come from the minority phase(s) in the sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network architecture\n",
    "\n",
    "We will make use of the hybrid ConvNeXt-Transformer architecture we used in the last post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "base_name = \"4-44-CuKa1-data_4000_\"\n",
    "root_dir = \"./\"\n",
    "cs = np.load(root_dir+base_name+\"crystal_systems_numeric.npy\")\n",
    "cs_key =  {\n",
    "    \"Cubic\" : 0,\n",
    "    \"Hexagonal\" :  1,\n",
    "    \"Monoclinic\" : 2,\n",
    "    \"Orthorhombic\" : 3,\n",
    "    \"Tetragonal\" : 4,\n",
    "    \"Triclinic\" : 5,\n",
    "    \"Trigonal (hexagonal axes)\" : 6,\n",
    "    \"Trigonal (rhombohedral axes)\" : 7\n",
    "}\n",
    "crystal_systems = np.unique(cs, return_counts=True)\n",
    "plt.bar(height=crystal_systems[1], x=[f\"{x} ({100*float(crystal_systems[1][i])/cs.shape[0]:.2f}%)\" for i, x in enumerate(list(cs_key.keys()))])\n",
    "plt.xticks(rotation=75)\n",
    "plt.title(f\"POW-COD data : {len(cs)} entries\")\n",
    "plt.show()\n",
    "\n",
    "cubic_data = np.where(cs == 0)[0]\n",
    "hex_data = np.where(cs == 1)[0]\n",
    "monoclinic_data = np.where(cs == 2)[0]\n",
    "orthorhombic_data = np.where(cs == 3)[0]\n",
    "tetrag_data = np.where(cs == 4)[0]\n",
    "triclinic_data = np.where(cs == 5)[0]\n",
    "# Ignore the trigonal!\n",
    "trimonoortho = np.sort(np.hstack([monoclinic_data, orthorhombic_data, triclinic_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffractionData(Dataset):\n",
    "\n",
    "    def __init__(self,base_name, root_dir=\"./\", idx=None, dtype=torch.float32):\n",
    "        if idx is not None:\n",
    "            self.crystal_system_numeric = torch.tensor(np.load(root_dir+base_name+\"crystal_systems_numeric.npy\")[idx], dtype=dtype)\n",
    "            self.hkl                    = torch.tensor(np.load(root_dir+base_name+\"hkl.npy\")[idx], dtype=dtype)\n",
    "            self.intensities            = torch.tensor(np.load(root_dir+base_name+\"intensities.npy\")[idx], dtype=dtype)\n",
    "            self.unit_cell              = torch.tensor(np.load(root_dir+base_name+\"unit_cell.npy\")[idx], dtype=dtype)\n",
    "            # Use extinctions rather than space groups\n",
    "            self.sg_number              = torch.tensor(np.load(root_dir+base_name+\"extinction_number.npy\")[idx], dtype=dtype)\n",
    "        else:\n",
    "            self.crystal_system_numeric = torch.tensor(np.load(root_dir+base_name+\"crystal_systems_numeric.npy\"), dtype=dtype)\n",
    "            self.hkl                    = torch.tensor(np.load(root_dir+base_name+\"hkl.npy\"), dtype=dtype)\n",
    "            self.intensities            = torch.tensor(np.load(root_dir+base_name+\"intensities.npy\"), dtype=dtype)\n",
    "            self.unit_cell              = torch.tensor(np.load(root_dir+base_name+\"unit_cell.npy\"), dtype=dtype)\n",
    "            # Use extinctions rather than space groups\n",
    "            self.sg_number              = torch.tensor(np.load(root_dir+base_name+\"extinction_number.npy\"), dtype=dtype)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.intensities)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.crystal_system_numeric[idx], self.hkl[idx], self.intensities[idx], self.unit_cell[idx], self.sg_number[idx]\n",
    "\n",
    "base_name = \"4-44-CuKa1-data_4000_\"\n",
    "root_dir = \"./\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available else \"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the data generation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation parameters\n",
    "\n",
    "from powcodgen import patterns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Data generation parameters\n",
    "# ------------------------------------------------------------\n",
    "ttmin = 4                       # Minimum data twotheta angle\n",
    "ttmax = 44                      # Maximum data twotheta angle\n",
    "peakrange = 3.                  # Buffer for peaks to move beyond the data range\n",
    "datadim = 2048                  # Number of points in PXRD histograms\n",
    "same_hwhm = False               # Impurity data has same peak shape & hwhm as the dominant phase\n",
    "min_impurity_intensity = 0.02   # Minimum intensity for impurity peaks\n",
    "max_impurity_intensity = 0.15   # Maximum intensity for impurity peaks\n",
    "add_background = True           # Include an amorphous background (Chebyshev)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Create the tensors used as the PXRD histograms\n",
    "full_data = torch.linspace(ttmin-(peakrange/2), ttmax+(peakrange/2),\n",
    "                        int(np.ceil((ttmax-ttmin+peakrange)/((ttmax-ttmin)/datadim))),\n",
    "                        device=device, dtype=dtype)\n",
    "x = (full_data[full_data <= ttmin+(peakrange/2)]).clone() - ttmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "class GRN(nn.Module):\n",
    "    \"\"\" Global Response Normalization, proposed in ConvNeXt v2 paper \"\"\"\n",
    "\n",
    "    def __init__(self, dim, eps = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.gamma = nn.Parameter(torch.zeros(1, dim, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, dim, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = (B, C, T)\n",
    "        # Want to average first over length (T), then divide by average channel (i.e. average of C)\n",
    "        # Divide the L2 norms by the average for each channel\n",
    "        Gx = x.norm(p=2, dim=2, keepdim=True) # (B, C, T) --> (B, C, 1)\n",
    "        Nx = Gx / Gx.mean(dim=1, keepdim=True).clamp(min=self.eps) # (B, C, 1) / (B, 1, 1) --> (B, C, 1)\n",
    "        return self.gamma * (x * Nx) + self.beta + x\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    \"\"\" DropPath regularisation can be used if needed, as described here:\n",
    "    https://arxiv.org/abs/1605.07648v4\n",
    "    \"\"\"\n",
    "    def __init__(self, p: float = 0.5, inplace: bool = False):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def drop_path(self, x, keep_prob: float = 1.0, inplace: bool = False):\n",
    "        mask = x.new_empty(x.shape[0], 1, 1).bernoulli_(keep_prob)\n",
    "        mask.div_(keep_prob)\n",
    "        if inplace:\n",
    "            x.mul_(mask)\n",
    "        else:\n",
    "            x = x * mask\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.p > 0:\n",
    "            x = self.drop_path(x, self.p, self.inplace)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(p={self.p})\"\n",
    "\n",
    "class ConvNeXtBlock(nn.Module):\n",
    "    # A 1D ConvNeXt v2 block\n",
    "    def __init__(self, dim, drop_path_prob=0.0):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv1d(in_channels=dim, out_channels=dim, kernel_size=7, groups=dim, padding=3)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.pwconv_1 = nn.Conv1d(dim, 4*dim, kernel_size=1, padding=0)\n",
    "        self.act = nn.GELU()\n",
    "        self.GRN = GRN(4*dim)\n",
    "        self.pwconv_2 = nn.Conv1d(4*dim, dim, kernel_size=1, padding=0)\n",
    "        self.droppath = DropPath(p=drop_path_prob)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Inputs has shape (B, C, T)\n",
    "        x = self.dwconv(inputs)\n",
    "        x = self.norm(x.permute(0,2,1))\n",
    "        x = x.permute(0,2,1) # Layernorm expects channels last\n",
    "        x = self.pwconv_1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.GRN(x)\n",
    "        x = self.pwconv_2(x)\n",
    "        return inputs + self.droppath(x)\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(in_dim)\n",
    "        self.down = nn.Conv1d(in_dim, out_dim, kernel_size=7, stride=2, padding=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x.permute(0, 2, 1)).permute(0,2,1)\n",
    "        x = self.down(x)\n",
    "        return x\n",
    "\n",
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(self, out_dim=3, depths=[2, 2, 6, 2], dims=[40, 80, 160, 320], drop_path_prob=0.5, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        self.initial_conv = nn.Conv1d(1, dims[0], kernel_size=7, stride=2, padding=3)\n",
    "        self.initial_norm = nn.LayerNorm(dims[0])\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i, dd in enumerate(zip(depths, dims)):\n",
    "            depth, dim = dd\n",
    "            for d in range(depth):\n",
    "                self.layers.append(ConvNeXtBlock(dim, drop_path_prob=drop_path_prob))\n",
    "            if i+1 != len(dims):\n",
    "                self.layers.append(DownSample(in_dim=dim, out_dim=dims[i+1]))\n",
    "            else:\n",
    "                self.layers.append(DownSample(in_dim=dim, out_dim=dims[i]))\n",
    "        self.final_norm = nn.LayerNorm(1024)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(1024, 64),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, shapes=False):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_norm(x.permute(0,2,1)).permute(0,2,1)\n",
    "        if shapes:\n",
    "            print(x.shape)\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "            if shapes:\n",
    "                print(x.shape)\n",
    "        x = self.final_norm(F.gelu(self.flatten(x)))#.permute(0,2,1)).permute(0,2,1) # global average pooling, (B, C, T) -> (B, C)\n",
    "        #x = self.flatten(x)\n",
    "        if shapes:\n",
    "            print(x.shape)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "model = ConvNeXt(depths=[2,2,6,2], dims=[4,8,12,16]).to(device)\n",
    "_ = model(torch.randn(100,1,2048).to(device), shapes=False)\n",
    "print(\"Model parameters:\",sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "class GLU(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, act=F.gelu, bias=True):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, out_dim, bias=bias)\n",
    "        self.linear2 = nn.Linear(in_dim, out_dim, bias=bias)\n",
    "        self.act = act\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.linear1(x))*self.linear2(x)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.qk = nn.Linear(dim, 2*dim)\n",
    "        self.v = nn.Linear(dim, dim)\n",
    "        self.mhsa_out = nn.Linear(dim, dim, bias=False)\n",
    "        self.GLU = GLU(dim, (dim*3)//2, bias=False)\n",
    "        self.linear_out = nn.Linear((dim*3)//2, dim, bias=False)\n",
    "        self.ln1 = nn.LayerNorm(dim)\n",
    "        self.ln2 = nn.LayerNorm(dim)\n",
    "        self.pos = nn.Embedding(256, embedding_dim=dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def mhsa(self, x):\n",
    "        B, T, C = x.shape\n",
    "        q, k = self.qk(x + self.pos(torch.arange(x.shape[1], device=x.device))).chunk(2, dim=-1)\n",
    "        v = self.v(x)\n",
    "        q = q.reshape(B, self.heads, T, C//self.heads)\n",
    "        k = k.reshape(B, self.heads, T, C//self.heads)\n",
    "        v = v.reshape(B, self.heads, T, C//self.heads)\n",
    "        x = F.scaled_dot_product_attention(q, k, v)\n",
    "        x = x.reshape(B, T, C)\n",
    "        x = self.mhsa_out(x)\n",
    "        return x\n",
    "\n",
    "    def ffwd(self, x):\n",
    "        x = self.GLU(x)\n",
    "        x = self.linear_out(self.dropout(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mhsa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "class ConvNeXtTransformer(nn.Module):\n",
    "    def __init__(self, datadim=2048, depths=[2, 2, 6, 2], dims=[40, 80, 160, 320],\n",
    "                 transformer_layers=6, transformer_heads=2, drop_path_prob=0.1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.depths = depths\n",
    "        self.datadim = datadim\n",
    "        self.downsample_layers = nn.ModuleList() # stem and 3 intermediate downsampling conv layers\n",
    "        self.initial_conv = nn.Conv1d(1, dims[0], kernel_size=7, stride=2, padding=3)\n",
    "        self.initial_norm = nn.LayerNorm(dims[0])\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.transformer_layers = nn.ModuleList()\n",
    "        self.cls_token = nn.Embedding(1, dims[-1])\n",
    "        for i, dd in enumerate(zip(depths, dims)):\n",
    "            depth, dim = dd\n",
    "            for d in range(depth):\n",
    "                self.conv_layers.append(ConvNeXtBlock(dim, drop_path_prob=drop_path_prob))\n",
    "            if i+1 != len(dims):\n",
    "                self.conv_layers.append(DownSample(in_dim=dim, out_dim=dims[i+1]))\n",
    "        for i in range(transformer_layers):\n",
    "            self.transformer_layers.append(TransformerBlock(dims[-1], transformer_heads, dropout=dropout))\n",
    "        self.final_norm = nn.LayerNorm(dims[-1])\n",
    "        self.output_pure_impure = nn.Sequential(\n",
    "            GLU(dims[-1], 32),\n",
    "            nn.Linear(32, 1)\n",
    "            )\n",
    "        self.patch_classifier = nn.Conv1d(dims[-1], 16, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, shapes=False):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.initial_norm(x.permute(0,2,1)).permute(0,2,1)\n",
    "        if shapes:\n",
    "            print(x.shape)\n",
    "        for l in self.conv_layers:\n",
    "            x = l(x)\n",
    "            if shapes:\n",
    "                print(x.shape)\n",
    "        x = F.gelu(x)\n",
    "        # Now concatenate the CLS token with the output of the convolutional layers\n",
    "        cls = self.cls_token(torch.arange(1, device=x.device)).squeeze().expand(x.shape[0], -1).unsqueeze(-1)\n",
    "        x = torch.cat([cls, x], dim=-1)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        for l in self.transformer_layers:\n",
    "            x = l(x)\n",
    "            if shapes:\n",
    "                print(x.shape)\n",
    "        x = self.final_norm(x).permute(0,2,1)\n",
    "        if shapes:\n",
    "            print(x.shape)\n",
    "        x_pure_impure = self.output_pure_impure(x[:,:,0])\n",
    "        patch_pure_impure = self.patch_classifier(x[:,:,1:])\n",
    "        B, T, C = patch_pure_impure.shape\n",
    "        patch_pure_impure = patch_pure_impure.permute(0,2,1).reshape(B, T*C)\n",
    "        if shapes:\n",
    "            print(x_pure_impure.shape, patch_pure_impure.shape)\n",
    "        return x_pure_impure, patch_pure_impure\n",
    "\n",
    "model = ConvNeXtTransformer(depths=[2,2,6,2], dims=[4,8,12,16], transformer_layers=6, transformer_heads=2).to(device)\n",
    "_ = model(torch.randn(100,1,2048).to(device), shapes=False)\n",
    "print(\"Model parameters:\",sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "# Training / validation code\n",
    "def get_loss(dataloader, model, optimizer, epoch, train=True, show_pbar=True, impure_peak_threshold=2.5e-2, plot=True):\n",
    "    \"\"\"\n",
    "    Get the losses for an epoch. Toggle between the dataloaders so the same code can be recycled\n",
    "    for the training and validation sets.\n",
    "    \"\"\"\n",
    "    if show_pbar:\n",
    "        pbar = tqdm(dataloader)\n",
    "    else:\n",
    "        pbar = dataloader\n",
    "    logs = []\n",
    "    if not train:\n",
    "        model.eval()\n",
    "    for batch_cs, batch_hkl, batch_i, batch_cell, batch_sg_number in pbar:\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # forward + backward + optimize\n",
    "        if len(batch_cs) % 2 != 0 or len(batch_cs) % 3 != 0:\n",
    "            maxlength = 6*(batch_cs.shape[0]//6)\n",
    "            batch_cs = batch_cs[:maxlength]\n",
    "            batch_hkl = batch_hkl[:maxlength]\n",
    "            batch_i = batch_i[:maxlength]\n",
    "            batch_cell = batch_cell[:maxlength]\n",
    "            batch_sg_number = batch_sg_number[:maxlength]\n",
    "        calcdata = patterns.calculate_diffraction_patterns_with_impurities(\n",
    "                                        x,\n",
    "                                        full_data,\n",
    "                                        batch_cs.to(device),\n",
    "                                        batch_hkl.to(device),\n",
    "                                        batch_i.to(device),\n",
    "                                        batch_cell.to(device),\n",
    "                                        batch_sg_number.to(device),\n",
    "                                        same_hwhm=same_hwhm,\n",
    "                                        min_impurity_intensity=min_impurity_intensity,\n",
    "                                        max_impurity_intensity=max_impurity_intensity,\n",
    "                                        add_background = add_background,\n",
    "                                    )\n",
    "        combined, pure_patterns, impure_patterns, pure_impure, cs, cell, sgs, hkls = calcdata\n",
    "        pred_pure, pred_peaks = model(combined.unsqueeze(1))\n",
    "        impurepeaks = ((impure_patterns - pure_patterns) > impure_peak_threshold).type(dtype)\n",
    "        pure_impure_bce = F.binary_cross_entropy_with_logits(pred_pure.squeeze(), pure_impure)\n",
    "        pure_imp_acc = ((F.sigmoid(pred_pure.squeeze()) > 0.5).type(dtype) == pure_impure).sum() / pure_impure.shape[0]\n",
    "        pred_peaks_bce = F.binary_cross_entropy_with_logits(pred_peaks.squeeze(), impurepeaks)\n",
    "        #print(pred_peaks.shape, impurepeaks.shape)\n",
    "        #return None\n",
    "        if train:\n",
    "            loss = pure_impure_bce + pred_peaks_bce\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        if show_pbar:\n",
    "            pbar.set_description_str(f\"Epoch: {epoch+1} P/I BCE: {pure_impure_bce.item():.3f} P/I acc: {pure_imp_acc.item():.3f} Peaks BCE : {pred_peaks_bce.item():.3f}\")\n",
    "        logs.append(torch.tensor([[]]))\n",
    "    if not train:\n",
    "        if plot:\n",
    "            for i in range(5):\n",
    "                plt.plot(combined[i].cpu())\n",
    "                plt.plot(-1*impure_patterns[i].cpu()-0.05)\n",
    "                plt.plot(impurepeaks[i].cpu())\n",
    "                plt.plot(F.sigmoid(pred_peaks[i]).detach().cpu())\n",
    "                plt.title(f\"{100*F.sigmoid(pred_pure[i]).detach().item():.2f}\")\n",
    "                plt.show()\n",
    "        model.train()\n",
    "    return logs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = (128*3)//2\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 50\n",
    "impure_peak_threshold = 2.5e-3\n",
    "idx = None # Train on all data, not a subset\n",
    "show_pbar = True\n",
    "model = ConvNeXtTransformer(depths=[2,2,6,2],\n",
    "                            dims=[4,8,16,32],\n",
    "                            transformer_layers=6, \n",
    "                            transformer_heads=2,\n",
    "                            drop_path_prob=0,\n",
    "                            dropout=0,\n",
    "                        ).to(device)\n",
    "print(\"Model parameters:\",sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate, betas=(0.9, 0.99), weight_decay=0.01)\n",
    "\n",
    "dataset = DiffractionData(base_name, root_dir=root_dir, idx=idx)\n",
    "g = torch.Generator().manual_seed(42)\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [0.8, 0.2], g)\n",
    "\n",
    "train_dataloader = DataLoader(train_set, batch_size=batchsize, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_set,   batch_size=batchsize, shuffle=True)\n",
    "\n",
    "print(f\"Training samples = {len(train_set)}\\nValidation samples = {len(val_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = (len(train_set)//batchsize) * num_epochs\n",
    "print(f\"Epochs: {num_epochs} Total gradient updates: {num_steps}\")\n",
    "\n",
    "all_train_losses = []\n",
    "all_val_losses = []\n",
    "best_val_mape = float(\"inf\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_losses = get_loss(train_dataloader, model, optimizer, epoch, train=True, show_pbar=show_pbar, impure_peak_threshold=impure_peak_threshold)\n",
    "    all_train_losses.append(train_losses)\n",
    "    train_losses = torch.cat(train_losses, dim=0).mean(dim=0)\n",
    "\n",
    "    val_losses = get_loss(val_dataloader, model, optimizer, epoch, train=False, show_pbar=show_pbar, impure_peak_threshold=impure_peak_threshold)\n",
    "    all_val_losses.append(val_losses)\n",
    "    val_losses = torch.cat(val_losses, dim=0).mean(dim=0)\n",
    "    if show_pbar:\n",
    "        #print(f\"Train: MSE {train_losses[0]:.3f} MAE {train_losses[1]:.3f} MAPE {train_losses[2]:.3f} Huber {train_losses[3]:.3f}\")\n",
    "        #print(f\"  Val: MSE {val_losses[0]:.3f} MAE {val_losses[1]:.3f} MAPE {val_losses[2]:.3f} Huber {val_losses[3]:.3f}\")\n",
    "        pass\n",
    "    #if val_losses[2] < best_val_mape:\n",
    "    #    #best_val_mape = val_losses[2]\n",
    "    #    #torch.save({\n",
    "    #    #    'epoch': epoch,\n",
    "    #    #    'model_state_dict': model.state_dict(),\n",
    "    #    #    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #    #    }, f\"saved_models/{name}.pth\")\n",
    "    #    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
